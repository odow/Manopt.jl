<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>get Started: Optimize! · Manopt.jl</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../index.html"><img src="../assets/logo.png" alt="Manopt.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit">Manopt.jl</span></div><form class="docs-search" action="../search.html"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../index.html">Home</a></li><li><a class="tocitem" href="../about.html">About</a></li><li><span class="tocitem">How to...</span><ul><li class="is-active"><a class="tocitem" href="MeanAndMedian.html">get Started: Optimize!</a><ul class="internal"><li><a class="tocitem" href="#Example-1"><span>Example</span></a></li><li><a class="tocitem" href="#The-given-Dataset-1"><span>The given Dataset</span></a></li><li><a class="tocitem" href="#Computing-the-Mean-1"><span>Computing the Mean</span></a></li><li><a class="tocitem" href="#Computing-the-Median-1"><span>Computing the Median</span></a></li><li><a class="tocitem" href="#Literature-1"><span>Literature</span></a></li></ul></li><li><a class="tocitem" href="GeodesicRegression.html">Do Geodesic regression</a></li><li><a class="tocitem" href="HowToRecord.html">Record values</a></li><li><a class="tocitem" href="StochasticGradientDescent.html">do stochastic gradient descent</a></li><li><a class="tocitem" href="BezierCurves.html">work with Bézier curves</a></li><li><a class="tocitem" href="GradientOfSecondOrderDifference.html">see the gradient of <span>$d_2$</span></a></li><li><a class="tocitem" href="JacobiFields.html">use Jacobi Fields</a></li><li><a class="tocitem" href="../pluto/AutomaticDifferentiation.html">AD in Manopt</a></li></ul></li><li><span class="tocitem">Plans</span><ul><li><a class="tocitem" href="../plans/index.html">Specify a Solver</a></li><li><a class="tocitem" href="../plans/problem.html">Problem</a></li><li><a class="tocitem" href="../plans/options.html">Options</a></li><li><a class="tocitem" href="../plans/stepsize.html">Stepsize</a></li></ul></li><li><span class="tocitem">Solvers</span><ul><li><a class="tocitem" href="../solvers/index.html">Introduction</a></li><li><a class="tocitem" href="../solvers/alternating_gradient_descent.html">Alternating Gradient Descent</a></li><li><a class="tocitem" href="../solvers/ChambollePock.html">Chambolle-Pock</a></li><li><a class="tocitem" href="../solvers/conjugate_gradient_descent.html">Conjugate gradient descent</a></li><li><a class="tocitem" href="../solvers/cyclic_proximal_point.html">Cyclic Proximal Point</a></li><li><a class="tocitem" href="../solvers/DouglasRachford.html">Douglas–Rachford</a></li><li><a class="tocitem" href="../solvers/gradient_descent.html">Gradient Descent</a></li><li><a class="tocitem" href="../solvers/NelderMead.html">Nelder–Mead</a></li><li><a class="tocitem" href="../solvers/particle_swarm.html">Particle Swarm Optimization</a></li><li><a class="tocitem" href="../solvers/quasi_Newton.html">Quasi-Newton</a></li><li><a class="tocitem" href="../solvers/stochastic_gradient_descent.html">Stochastic Gradient Descent</a></li><li><a class="tocitem" href="../solvers/subgradient.html">Subgradient method</a></li><li><a class="tocitem" href="../solvers/truncated_conjugate_gradient_descent.html">Steihaug-Toint TCG Method</a></li><li><a class="tocitem" href="../solvers/trust_regions.html">Trust-Regions Solver</a></li></ul></li><li><span class="tocitem">Functions</span><ul><li><a class="tocitem" href="../functions/index.html">Introduction</a></li><li><a class="tocitem" href="../functions/bezier.html">Bézier curves</a></li><li><a class="tocitem" href="../functions/costs.html">Cost functions</a></li><li><a class="tocitem" href="../functions/differentials.html">Differentials</a></li><li><a class="tocitem" href="../functions/adjointdifferentials.html">Adjoint Differentials</a></li><li><a class="tocitem" href="../functions/gradients.html">Gradients</a></li><li><a class="tocitem" href="../functions/Jacobi_fields.html">Jacobi Fields</a></li><li><a class="tocitem" href="../functions/proximal_maps.html">Proximal Maps</a></li><li><a class="tocitem" href="../functions/manifold.html">Specific Manifold Functions</a></li></ul></li><li><span class="tocitem">Helpers</span><ul><li><a class="tocitem" href="../helpers/checks.html">Checks</a></li><li><a class="tocitem" href="../helpers/data.html">Data</a></li><li><a class="tocitem" href="../helpers/errorMeasures.html">Error Measures</a></li><li><a class="tocitem" href="../helpers/exports.html">Exports</a></li></ul></li><li><a class="tocitem" href="../contributing.html">Contributing to Manopt.jl</a></li><li><a class="tocitem" href="../notation.html">Notation</a></li><li><a class="tocitem" href="../list.html">Function Index</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">How to...</a></li><li class="is-active"><a href="MeanAndMedian.html">get Started: Optimize!</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href="MeanAndMedian.html">get Started: Optimize!</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaManifolds/Manopt.jl/blob/master/src/tutorials/MeanAndMedian.jl" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Optimize-1"><a class="docs-heading-anchor" href="#Optimize-1">Get started: Optimize!</a><a class="docs-heading-anchor-permalink" href="#Optimize-1" title="Permalink"></a></h1><p>This example illustrates how to set up and solve optimization problems and how to further get data from the algorithm using <a href="../plans/options.html#Manopt.DebugOptions"><code>DebugOptions</code></a> and <a href="../plans/options.html#Manopt.RecordOptions"><code>RecordOptions</code></a>. We will use the Riemannian mean and median as simple examples.</p><p>To start from the quite general case: A <strong>Solver</strong> is an algorithm that aims to solve</p><div>\[\operatorname*{argmin}_{x∈\mathcal M} f(x)\]</div><p>where <span>$\mathcal M$</span> is a <a href="https://juliamanifolds.github.io/Manifolds.jl/stable/interface.html#ManifoldsBase.Manifold">Manifold</a> and <span>$f:\mathcal M → ℝ$</span> is the cost function.</p><p>In <code>Manopt.jl</code> a <strong>Solver</strong> is an algorithm that requires a <a href="../plans/problem.html#Manopt.Problem"><code>Problem</code></a> <code>p</code> and <a href="../plans/options.html#Manopt.Options"><code>Options</code></a> <code>o</code>. While former contains <strong>static</strong> data, most prominently the manifold <span>$\mathcal M$</span> (usually as <code>p.M</code>) and the cost function <span>$f$</span> (usually as <code>x-&gt;get_cost(p, x)</code>), the latter contains <strong>dynamic</strong> data, i.e. things that usually change during the algorithm, are allowed to change, or specify the details of the algorithm to use. Together they form a <code>plan</code>. A <code>plan</code> uniquely determines the algorithm to use and provide all necessary information to run the algorithm.</p><h2 id="Example-1"><a class="docs-heading-anchor" href="#Example-1">Example</a><a class="docs-heading-anchor-permalink" href="#Example-1" title="Permalink"></a></h2><p>A gradient plan consists of a <a href="../plans/problem.html#Manopt.GradientProblem"><code>GradientProblem</code></a> with the fields <code>M</code>, cost function <span>$f$</span> as well as <code>gradient</code> storing the gradient function corresponding to <span>$f$</span>. Accessing both functions can be done directly but should be encapsulated using <a href="../plans/problem.html#Manopt.get_cost"><code>get_cost</code></a><code>(p,x)</code> and <a href="../plans/problem.html#Manopt.get_gradient"><code>get_gradient</code></a><code>(p,x)</code>, where in both cases <code>x</code> is a point on the <a href="https://juliamanifolds.github.io/Manifolds.jl/stable/interface.html#ManifoldsBase.Manifold">Manifold</a> <code>M</code>. Second, the <a href="../solvers/gradient_descent.html#Manopt.GradientDescentOptions"><code>GradientDescentOptions</code></a> specify that the algorithm to solve the <a href="../plans/problem.html#Manopt.GradientProblem"><code>GradientProblem</code></a> will be the <a href="https://en.wikipedia.org/wiki/Gradient_descent">gradient descent</a> algorithm. It requires an initial value <code>o.x0</code>, a <a href="../solvers/index.html#Manopt.StoppingCriterion"><code>StoppingCriterion</code></a> <code>o.stop</code>, a <a href="../plans/stepsize.html#Manopt.Stepsize"><code>Stepsize</code></a> <code>o.stepsize</code> and a retraction <code>o.retraction</code> and it internally stores the last evaluation of the gradient at <code>o.gradient</code> for convenience. The only mandatory parameter is the initial value <code>x0</code>, though the defaults for both the stopping criterion (<a href="../solvers/index.html#Manopt.StopAfterIteration"><code>StopAfterIteration</code></a><code>(100)</code>) as well as the stepsize (<a href="../plans/stepsize.html#Manopt.ConstantStepsize"><code>ConstantStepsize</code></a><code>(1.)</code> are quite conservative, but are chosen to be as simple as possible.</p><p>With these two at hand, running the algorithm just requires to call <code>x_opt = solve(p,o)</code>.</p><p>In the following two examples we will see, how to use a higher level interface that allows to more easily activate for example a debug output or record values during the iterations</p><h2 id="The-given-Dataset-1"><a class="docs-heading-anchor" href="#The-given-Dataset-1">The given Dataset</a><a class="docs-heading-anchor-permalink" href="#The-given-Dataset-1" title="Permalink"></a></h2><pre><code class="language-julia">using Manopt, Manifolds
using Random, Colors</code></pre><p>For a persistent random set we use</p><pre><code class="language-julia">n = 100
σ = π / 8
M = Sphere(2)
x = 1 / sqrt(2) * [1.0, 0.0, 1.0]
Random.seed!(42)
data = [exp(M, x, random_tangent(M, x, Val(:Gaussian), σ)) for i in 1:n]</code></pre><p>and we define some colors from <a href="https://personal.sron.nl/~pault/">Paul Tol</a></p><pre><code class="language-julia">black = RGBA{Float64}(colorant&quot;#000000&quot;)
TolVibrantOrange = RGBA{Float64}(colorant&quot;#EE7733&quot;)
TolVibrantBlue = RGBA{Float64}(colorant&quot;#0077BB&quot;)
TolVibrantTeal = RGBA{Float64}(colorant&quot;#009988&quot;)
TolVibrantMagenta = RGBA{Float64}(colorant&quot;#EE3377&quot;)</code></pre><p>Then our data rendered using <a href="../helpers/exports.html#Manopt.asymptote_export_S2_signals-Tuple{String}"><code>asymptote_export_S2_signals</code></a> looks like</p><pre><code class="language-julia">asymptote_export_S2_signals(&quot;startDataAndCenter.asy&quot;;
    points = [ [x], data],
    colors=Dict(:points =&gt; [TolVibrantBlue, TolVibrantTeal]),
    dot_size = 3.5, camera_position = (1.,.5,.5)
)
render_asymptote(&quot;startDataAndCenter.asy&quot;; render = 2)</code></pre><p><img src="../assets/images/tutorials/startDataAndCenter.png" alt="The data of noisy versions of \$x\$"/></p><h2 id="Computing-the-Mean-1"><a class="docs-heading-anchor" href="#Computing-the-Mean-1">Computing the Mean</a><a class="docs-heading-anchor-permalink" href="#Computing-the-Mean-1" title="Permalink"></a></h2><p>To compute the mean on the manifold we use the characterization, that the Euclidean mean minimizes the sum of squared distances, and end up with the following cost function. Its minimizer is called <a href="https://arxiv.org/abs/1407.2087">Riemannian Center of Mass</a>.</p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>There are more sophisticated methods tailored for the specific manifolds available in <a href="https://juliamanifolds.github.io/Manifolds.jl/">Manifolds.jl</a> see <a href="https://juliamanifolds.github.io/Manifolds.jl/stable/features/statistics.html#Statistics.mean-Tuple{Manifold,AbstractArray{T,1}%20where%20T,AbstractArray{T,1}%20where%20T,ExtrinsicEstimation}"><code>mean</code></a>.</p></div></div><pre><code class="language-julia">F(M, y) = sum(1 / (2 * n) * distance.(Ref(M), Ref(y), data) .^ 2)
gradF(M, y) = sum(1 / n * grad_distance.(Ref(M), data, Ref(y)))</code></pre><p>note that the <a href="../functions/gradients.html#Manopt.grad_distance"><code>grad_distance</code></a> defaults to the case <code>p=2</code>, i.e. the gradient of the squared distance. For details on convergence of the gradient descent for this problem, see [<a href="#AfsariTronVidal2013">Afsari, Tron, Vidal, 2013</a>]</p><p>The easiest way to call the gradient descent is now to call <a href="../solvers/gradient_descent.html#Manopt.gradient_descent"><code>gradient_descent</code></a></p><pre><code class="language-julia">xMean = gradient_descent(M, F, gradF, data[1])</code></pre><p>but in order to get more details, we further add the <code>debug=</code> options, which act as a <a href="https://en.wikipedia.org/wiki/Decorator_pattern">decorator pattern</a> using the <a href="../plans/options.html#Manopt.DebugOptions"><code>DebugOptions</code></a> and <a href="../plans/options.html#Manopt.DebugAction"><code>DebugAction</code></a>s. The latter store values if that&#39;s necessary, for example for the <a href="../plans/options.html#Manopt.DebugChange"><code>DebugChange</code></a> that prints the change during the last iteration. The following debug prints</p><p><code># i | x: | Last Change: | F(x):</code>`</p><p>as well as the reason why the algorithm stopped at the end. Here, the format shorthand and the [<code>DebugFactory</code>] are used, which returns a <a href="../plans/options.html#Manopt.DebugGroup"><code>DebugGroup</code></a> of <a href="../plans/options.html#Manopt.DebugAction"><code>DebugAction</code></a> performed each iteration and the stop, respectively.</p><pre><code class="language-julia">xMean = gradient_descent(
    M,
    F,
    gradF,
    data[1];
    debug=[:Iteration, &quot; | &quot;, :x, &quot; | &quot;, :Change, &quot; | &quot;, :Cost, &quot;\n&quot;, :Stop],
)</code></pre><pre><code class="language-none">Initial | x: [0.5737338264338113, -0.1728651513118652, 0.8005917410687816] |  | F(x): 0.226061
# 1      | x: [0.8522490143981754, 0.22993371406522728, 0.46989584440970433] | Last Change: 0.599866 | F(x): 0.167387
# 2      | x: [0.7526113561098337, 0.02974203956103383, 0.6577929444264867] | Last Change: 0.293127 | F(x): 0.153439
# 3      | x: [0.8086254694158463, 0.1315529090368081, 0.5734271377742384] | Last Change: 0.143722 | F(x): 0.150092
# 4      | x: [0.7839032763546996, 0.08068908392749388, 0.6156175152278478] | Last Change: 0.070572 | F(x): 0.149286
# 5      | x: [0.7961745826103945, 0.10627288973401836, 0.5956610671453568] | Last Change: 0.034691 | F(x): 0.149091
# 6      | x: [0.7904421869345579, 0.09345333865089521, 0.6053656932872182] | Last Change: 0.017070 | F(x): 0.149044
# 7      | x: [0.7932020797469317, 0.09988719024475129, 0.600710421010116] | Last Change: 0.008407 | F(x): 0.149033
# 8      | x: [0.7918940709797025, 0.09666118136442839, 0.6029596971310991] | Last Change: 0.004145 | F(x): 0.149030
# 9      | x: [0.7925187329183903, 0.0982792446742766, 0.6018764391797395] | Last Change: 0.002045 | F(x): 0.149029
# 10     | x: [0.7922216903621498, 0.0974679019303884, 0.602399204359556] | Last Change: 0.001010 | F(x): 0.149029
# 11     | x: [0.7923631935189425, 0.09787473812377014, 0.6021470793698716] | Last Change: 0.000499 | F(x): 0.149029
# 12     | x: [0.7922958757234528, 0.09767076084988602, 0.6022687670688321] | Last Change: 0.000247 | F(x): 0.149029
# 13     | x: [0.7923279085300854, 0.09777302472506591, 0.6022100306375279] | Last Change: 0.000122 | F(x): 0.149029
# 14     | x: [0.7923126750872849, 0.0977217589019443, 0.6022383936060045] | Last Change: 0.000061 | F(x): 0.149029
# 15     | x: [0.7923199180065943, 0.09774745737571369, 0.602224694035878] | Last Change: 0.000030 | F(x): 0.149029
# 16     | x: [0.7923164757880922, 0.09773457611727027, 0.6022313133887304] | Last Change: 0.000015 | F(x): 0.149029
# 17     | x: [0.7923181111408605, 0.09774103241847028, 0.6022281140398135] | Last Change: 0.000007 | F(x): 0.149029
# 18     | x: [0.792317334541356, 0.09773779659988897, 0.6022296609276893] | Last Change: 0.000004 | F(x): 0.149029
# 19     | x: [0.7923177031769476, 0.097739418264318, 0.6022289127481001] | Last Change: 0.000002 | F(x): 0.149029
# 20     | x: [0.7923175282756361, 0.0977386055925994, 0.602229274748414] | Last Change: 0.000001 | F(x): 0.149029
# 21     | x: [0.7923176112177297, 0.0977390128301025, 0.6022290995337466] | Last Change: 0.000000 | F(x): 0.149029
# 22     | x: [0.7923175719055521, 0.09773880876920807, 0.6022291843725825] | Last Change: 0.000000 | F(x): 0.149029
# 23     | x: [0.7923175905279262, 0.09773891101658343, 0.6022291432779665] | Last Change: 0.000000 | F(x): 0.149029
# 24     | x: [0.7923175817117204, 0.09773885978641349, 0.6022291631913409] | Last Change: 0.000000 | F(x): 0.149029
# 25     | x: [0.792317585882808, 0.09773888545379272, 0.6022291535379944] | Last Change: 0.000000 | F(x): 0.149029
# 26     | x: [0.7923175839107578, 0.09773887259440858, 0.6022291582195209] | Last Change: 0.000000 | F(x): 0.149029
The algorithm reached approximately critical point after 26 iterations; the gradient norm (8.802161844673062e-9) is less than 1.0e-8.</code></pre><p>A way to get better performance and for convex and coercive costs a guaranteed convergence is to switch the default <a href="../plans/stepsize.html#Manopt.ConstantStepsize"><code>ConstantStepsize</code></a>(1.0) with a step size that performs better, for example the <a href="../plans/stepsize.html#Manopt.ArmijoLinesearch"><code>ArmijoLinesearch</code></a>(). We can tweak the default values for the contractionFactor and the sufficientDecrease beyond constant step size which is already quite fast.  This gives</p><pre><code class="language-julia">xMean2 = gradient_descent(
    M,
    F,
    gradF,
    data[1];
    stepsize=ArmijoLinesearch(1.0, ExponentialRetraction(), 0.99, 0.5),
    debug=[:Iteration, &quot; | &quot;, :x, &quot; | &quot;, :Change, &quot; | &quot;, :Cost, &quot;\n&quot;, :Stop],
)</code></pre><pre><code class="language-none">3-element Vector{Float64}:
 0.7923175845434248
 0.09773887689071527
 0.6022291566898887</code></pre><p>which finishes in 5 steaps, just slightly better than the previous computation.</p><pre><code class="language-julia">F(M, xMean) - F(M, xMean2)</code></pre><pre><code class="language-none">2.7755575615628914e-16</code></pre><p>Note that other optimization tasks may have other speedup opportunities.</p><p>For even more precision, we can further require a smaller gradient norm. This is done by changing the <a href="../solvers/index.html#Manopt.StoppingCriterion"><code>StoppingCriterion</code></a> used, where several criteria can be combined using <code>&amp;</code> and/or <code>|</code>.  If we want to decrease the final gradient (from less that 1e-8) norm but keep the maximal number of iterations to be 200, we can run</p><pre><code class="language-julia">xMean3 = gradient_descent(
    M,
    F,
    gradF,
    data[1];
    stepsize=ArmijoLinesearch(1.0, ExponentialRetraction(), 0.99, 0.5),
    stopping_criterion=StopAfterIteration(200) | StopWhenGradientNormLess(1e-15),
    debug=[:Iteration, &quot; | &quot;, :x, &quot; | &quot;, :Change, &quot; | &quot;, :Cost, &quot;\n&quot;, :Stop],
)</code></pre><pre><code class="language-none">3-element Vector{Float64}:
 0.7923175845436087
 0.0977388768865157
 0.6022291566903284</code></pre><p>which takes 10 iterations but gets a very small gradient, and not much is gained in the cost itself</p><pre><code class="language-julia">F(M, xMean2) - F(M, xMean3)</code></pre><pre><code class="language-none">0.0</code></pre><pre><code class="language-julia">asymptote_export_S2_signals(&quot;startDataCenterMean.asy&quot;;
    points = [ [x], data, [xMean] ],
    colors=Dict(:points =&gt; [TolVibrantBlue, TolVibrantTeal, TolVibrantOrange]),
    dot_size = 3.5, camera_position = (1.,.5,.5)
)
render_asymptote(&quot;startDataCenterMean.asy&quot;; render = 2)</code></pre><p><img src="../assets/images/tutorials/startDataCenterMean.png" alt="The resulting mean (orange)"/></p><h2 id="Computing-the-Median-1"><a class="docs-heading-anchor" href="#Computing-the-Median-1">Computing the Median</a><a class="docs-heading-anchor-permalink" href="#Computing-the-Median-1" title="Permalink"></a></h2><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>There are more sophisticated methods tailored for the specific manifolds available in <a href="https://juliamanifolds.github.io/Manifolds.jl/">Manifolds.jl</a> see <a href="https://juliamanifolds.github.io/Manifolds.jl/stable/features/statistics.html#Statistics.median-Tuple{Manifold,AbstractArray{T,1}%20where%20T,AbstractArray{T,1}%20where%20T,CyclicProximalPointEstimation}"><code>median</code></a>.</p></div></div><p>Similar to the mean you can also define the median as the minimizer of the distances, see for example [<a href="#Bačák2014">Bačák, 2014</a>], but since this problem is not differentiable, we employ the Cyclic Proximal Point (CPP) algorithm, described in the same reference. We define</p><pre><code class="language-julia">F2(M, y) = sum(1 / (2 * n) * distance.(Ref(M), Ref(y), data))
proxes = Function[(M, λ, y) -&gt; prox_distance(M, λ / n, di, y, 1) for di in data]</code></pre><p>where the <code>Function</code> is a helper for global scope to infer the correct type.</p><p>We then call the <a href="../solvers/cyclic_proximal_point.html#Manopt.cyclic_proximal_point"><code>cyclic_proximal_point</code></a> as</p><pre><code class="language-julia">o = cyclic_proximal_point(
    M,
    F2,
    proxes,
    data[1];
    debug=[:Iteration, &quot; | &quot;, :x, &quot; | &quot;, :Change, &quot; | &quot;, :Cost, &quot;\n&quot;, 50, :Stop],
    record=[:Iteration, :Change, :Cost],
    return_options=true,
)
xMedian = get_solver_result(o)
values = get_record(o)</code></pre><pre><code class="language-none">Initial | x: [0.5737338264338113, -0.1728651513118652, 0.8005917410687816] |  | F(x): 0.298680
# 50     | x: [0.7897340334179458, 0.07829927185150312, 0.608431902918448] | Last Change: 0.080252 | F(x): 0.245454
# 100    | x: [0.7899680461384707, 0.0786029490954357, 0.6080888606722517] | Last Change: 0.000493 | F(x): 0.245454
# 150    | x: [0.790036413163267, 0.07868191382352602, 0.6079898208960562] | Last Change: 0.000139 | F(x): 0.245454
# 200    | x: [0.7900676764403393, 0.0787154178585569, 0.6079448573970901] | Last Change: 0.000062 | F(x): 0.245454
# 250    | x: [0.7900851818616217, 0.07873311977053307, 0.6079198148226581] | Last Change: 0.000034 | F(x): 0.245454
The algorithm performed a step with a change (0.0) less than 1.0e-12.</code></pre><p>where the differences to <a href="../solvers/gradient_descent.html#Manopt.gradient_descent"><code>gradient_descent</code></a> are as follows</p><ul><li>the third parameter is now an Array of proximal maps</li><li>debug is reduces to only every 50th iteration</li><li>we further activated a <a href="../plans/options.html#Manopt.RecordAction"><code>RecordAction</code></a> using the <code>record=</code> optional parameter. These work very similar to those in debug, but they collect their data in an array. The high level interface then returns two variables; the <code>values</code> do contain an array of recorded datum per iteration. Here a Tuple containing the iteration, last change and cost respectively; see <a href="../plans/options.html#Manopt.RecordGroup"><code>RecordGroup</code></a>, <a href="../plans/options.html#Manopt.RecordIteration"><code>RecordIteration</code></a>, <a href="../plans/options.html#Manopt.RecordChange"><code>RecordChange</code></a>, <a href="../plans/options.html#Manopt.RecordCost"><code>RecordCost</code></a> as well as the <a href="../plans/options.html#Manopt.RecordFactory-Tuple{Options, Vector{var&quot;#s10&quot;} where var&quot;#s10&quot;}"><code>RecordFactory</code></a> for details. The <code>values</code> contains hence a tuple per iteration, that itself consists of (by order of specification) the iteration number, the last change and the cost function value.</li></ul><p>These recorded entries read</p><pre><code class="language-julia">values</code></pre><pre><code class="language-none">254-element Vector{Tuple{Int64, Float64, Float64}}:
 (1, 0.0, 0.2476570982176944)
 (2, 0.03915137245269646, 0.24599998171726195)
 (3, 0.014699094618098311, 0.24568197834842026)
 (4, 0.0075130396403671924, 0.2455730592919036)
 (5, 0.0044893480449786525, 0.2455249161082335)
 (6, 0.002953601317596155, 0.24550007064482604)
 (7, 0.0020748587403644106, 0.24548583414095707)
 (8, 0.0015286431209686094, 0.2454770356861027)
 (9, 0.001167743288968188, 0.2454712772782416)
 (10, 0.0009178169876077584, 0.24546733510439245)
 ⋮
 (246, 3.175031505921871e-7, 0.24545401932704827)
 (247, 2.976504617249705e-7, 0.24545401929389435)
 (248, 2.846862848779986e-7, 0.24545401926124036)
 (249, 2.669762502188827e-7, 0.24545401922907215)
 (250, 2.269677253324963e-7, 0.2454540191973801)
 (251, 1.659323085197815e-7, 0.24545401916615991)
 (252, 1.0745380149674388e-7, 0.2454540191354066)
 (253, 7.300048299977716e-8, 0.24545401910510922)
 (254, 0.0, 0.2454540190752502)</code></pre><p>The resulting median and mean for the data hence are</p><pre><code class="language-julia">asymptote_export_S2_signals(&quot;startDataCenterMean.asy&quot;;
    points = [ [x], data, [xMean], [xMedian] ],
    colors=Dict(:points =&gt; [TolVibrantBlue, TolVibrantTeal, TolVibrantOrange, TolVibrantMagenta]),
    dot_size = 3.5, camera_position = (1.,.5,.5)
)
render_asymptote(&quot;startDataCenterMedianAndMean.asy&quot;; render = 2)</code></pre><p><img src="../assets/images/tutorials/startDataCenterMedianAndMean.png" alt="The resulting mean (orange) and median (magenta)"/></p><h2 id="Literature-1"><a class="docs-heading-anchor" href="#Literature-1">Literature</a><a class="docs-heading-anchor-permalink" href="#Literature-1" title="Permalink"></a></h2><ul>
<li id="Bačák2014">[<a>Bačák, 2014</a>]
  Bačák, M: <emph>Computing Medians and Means in Hadamard Spaces.</emph>,
  SIAM Journal on Optimization, Volume 24, Number 3, pp. 1542–1566,
  doi: <a href="https://doi.org/10.1137/140953393">10.1137/140953393</a>,
  arxiv: <a href="https://arxiv.org/abs/1210.2145">1210.2145</a>.</li>
  <li id="AfsariTronVidal2013">[<a>Afsari, Tron, Vidal, 2013</a>]
   Afsari, B; Tron, R.; Vidal, R.: <emph>On the Convergence of Gradient
   Descent for Finding the Riemannian Center of Mass</emph>,
   SIAM Journal on Control and Optimization, Volume 51, Issue 3,
   pp. 2230–2260.
   doi: <a href="https://doi.org/10.1137/12086282X">10.1137/12086282X</a>,
   arxiv: <a href="https://arxiv.org/abs/1201.0925">1201.0925</a></li>
</ul></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../about.html">« About</a><a class="docs-footer-nextpage" href="GeodesicRegression.html">Do Geodesic regression »</a></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Saturday 23 April 2022 05:40">Saturday 23 April 2022</span>. Using Julia version 1.6.6.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
